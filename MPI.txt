Greetings:
#include<stdio.h>
#include<stdlib.h>
#include<mpi.h>
#include<string.h>


int main(int argc, char **argv)
{
    char send_greeting[50], recv_greeting[50];
    int process_rank, num_processes, method;


    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &process_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &num_processes);


    sprintf(send_greeting, "Greetings from process %d", process_rank);


    if(process_rank == 0)
    {
        printf("Select method 1 (all receive) or 2 (only root receives)\n");
        scanf("%d", &method);
    }


    MPI_Bcast(&method, 1, MPI_INT, 0, MPI_COMM_WORLD);


    if(method == 1)
    {
        for(int i = 0; i < num_processes; i++)
        {
            if(i != process_rank)
            {
                MPI_Bsend(send_greeting, strlen(send_greeting), MPI_CHAR, i, 0, MPI_COMM_WORLD);
            }
        }


        for(int i = 0; i < num_processes - 1; i++)
        {
            MPI_Recv(recv_greeting, 50, MPI_CHAR, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);


            printf("%s, process %d!\n", recv_greeting, process_rank);
        }
    }
    else
    {
        if(process_rank != 0)
        {
            MPI_Send(send_greeting, strlen(send_greeting), MPI_CHAR, 0, 0, MPI_COMM_WORLD);
        }
        else
        {
            for(int i = 1; i < num_processes; i++)
            {
                MPI_Recv(recv_greeting, 50, MPI_CHAR, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);


                printf("%s, root!\n", recv_greeting);
            }
        }
    }
    
    MPI_Finalize();
}


Sum Vectors:
#include<stdio.h>
#include<mpi.h>


int main(int argc, char **argv)
{
    int process_rank, num_processes;
    int i, n, n_p;
    int a[100], b[100], sum[100], a_p[100], b_p[100], sum_p[100];


    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &process_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &num_processes);


    if(process_rank == 0)
    {
        printf("Enter the length of the vectors\n");
        scanf("%d", &n);


        printf("Enter the elements of vector 1\n");
        for(i = 0; i < n; i++)
        {
            scanf("%d", &a[i]);
        }


        printf("Enter the elements of vector 2\n");
        for(i = 0; i < n; i++)
        {
            scanf("%d", &b[i]);
        }


        n_p = n / num_processes;
    }


    MPI_Bcast(&n_p, 1, MPI_INT, 0, MPI_COMM_WORLD);
    MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);


    MPI_Scatter(a, n_p, MPI_INT, a_p, n_p, MPI_INT, 0, MPI_COMM_WORLD);
    MPI_Scatter(b, n_p, MPI_INT, b_p, n_p, MPI_INT, 0, MPI_COMM_WORLD);


    for(i = 0; i < n_p; i++)
    {
        sum_p[i] = a_p[i] + b_p[i];
    }


    MPI_Gather(sum_p, n_p, MPI_INT, sum, n_p, MPI_INT, 0, MPI_COMM_WORLD);


    if(process_rank == 0)
    {
        printf("Resultant vector :-\n");


        for(i = 0; i < n; i++)
        {
            printf("%d ", sum[i]);
        }


        printf("\n");
    }


    MPI_Finalize();
    return 0;
}
Trapezoidal:
/*
 *  Prerequisties:
 *     This code runs using an MPI library, either OpenMPI or MPICH2.
 *     These libraries can be installed in either a cluster of computers
 *     or a multicore machine.
 *     
 *  How to compile:
 *     mpicc -o vec-add VA-MPI-simple.c
 *
 *  How to execute:
 *     mpirun -np 2 ./vec-add
 *
 *     Note that this executes the code on 2 processes, using the -np command line flag.
 *     See ideas for further exploration of MPI using this code at the end of this file.
 */




#include "mpi.h"      // must have a system with an MPI library
#include <stdio.h>    //printf
#include <stdlib.h>   //malloc


/*
 * Definitions
 */
#define MASTER 0         //One process will take care of initialization
#define ARRAY_SIZE 8     //Size of arrays that will be added together.


/*
 *  In MPI programs, the main function for the program is run on every
 *  process that gets initialized when you start up this code using mpirun.
 */
int main (int argc, char *argv[]) 
{
        // elements of arrays a and b will be added
        // and placed in array c
        int * a;
        int * b; 
        int * c;
        
        int total_proc;         // total nuber of processes        
        int rank;        // rank of each process
        int n_per_proc;        // elements per process        
        int n = ARRAY_SIZE;   // number of array elements
        int i;       // loop index
                
        MPI_Status status;   // not used in this arguably poor example
                             // that is devoid of error checking.


        // 1. Initialization of MPI environment
        MPI_Init (&argc, &argv);
        MPI_Comm_size (MPI_COMM_WORLD, &total_proc);
        // 2. Now you know the total number of processes running in parallel
        MPI_Comm_rank (MPI_COMM_WORLD,&rank);
        // 3. Now you know the rank of the current process
        
        // Smaller arrays that will be held on each separate process
            int * ap;
        int * bp;
        int * cp;
        
        // 4. We choose process rank 0 to be the root, or master,
        // which will be used to  initialize the full arrays.
        if (rank == MASTER)  {
                a = (int *) malloc(sizeof(int)*n);
                b = (int *) malloc(sizeof(int)*n);
                c = (int *) malloc(sizeof(int)*n);
                
                // initialize arrays a and b with consecutive integer values
                // as a simple example
                for(i=0;i<n;i++)
                        a[i] = i;
                for(i=0;i<n;i++)
                        b[i] = i;
        }
        
        // All processes take part in the calculations concurrently
                
        // determine how many elements each process will work on
        n_per_proc = n/total_proc;
        /////// NOTE:
        // In this simple version, the number of processes needs to
        // divide evenly into the number of elements in the array
        ///////////
        
        // 5. Initialize my smaller subsections of the larger array
        ap = (int *) malloc(sizeof(int)*n_per_proc);
        bp = (int *) malloc(sizeof(int)*n_per_proc);
        cp = (int *) malloc(sizeof(int)*n_per_proc);
        
        // 6.
        //scattering array a from MASTER node out to the other nodes
        MPI_Scatter(a, n_per_proc, MPI_INT, ap, n_per_proc, MPI_INT, MASTER, MPI_COMM_WORLD); 
        //scattering array b from MASTER node out to the other node
        MPI_Scatter(b, n_per_proc, MPI_INT, bp, n_per_proc, MPI_INT, MASTER, MPI_COMM_WORLD); 
        
        // 7. Compute the addition of elements in my subsection of the array
        for(i=0;i<n_per_proc;i++)
                cp[i] = ap[i]+bp[i];
        
        // 8. MASTER node gathering array c from the workers
        MPI_Gather(cp, n_per_proc, MPI_INT, c, n_per_proc, MPI_INT, MASTER, MPI_COMM_WORLD);


/////////////////////// all concurrent processes are finished once they all communicate
/////////////////////// data back to the master via the gather function.


        // Master process gets to here only when it has been able to gather from all processes
        if (rank == MASTER)  {                        
                // sanity check the result  (a test we would eventually leave out)
                int good = 1;
                for(i=0;i<n;i++) {
                        //printf ("%d ", c[i]);
                        if (c[i] != a[i] + b[i]) {
                                printf("problem at index %lld\n", i);
                                good = 0;
                                break;
                        }else{
                printf("%d  ", c[i]);
            }
                }
                if (good) {
                        printf ("Values correct!\n");
                }
                
        }


        // clean up memory
        if (rank == MASTER)  {
                free(a);  free(b); free(c);
        }
        free(ap);  free(bp); free(cp);
        
        // 9. Terminate MPI Environment and Processes
        MPI_Finalize();  
        
        return 0;
}


Get Input:
#include<stdio.h>
#include<mpi.h>


void get_input(double *a, double *b, int *n, int process_rank, int num_processes, int b_flag)
{
    MPI_Status status;
    double a_val = 0.0, b_val = 0.0;
    int n_val = 0;


    if(process_rank == 0)
    {
        printf("Enter a, b and n\n");
        scanf("%lf", &a_val);
        scanf("%lf", &b_val);
        scanf("%d", &n_val);


        a = &a_val;
        b = &b_val;
        n = &n_val;
    }


    if(b_flag == 0)
    {
        if(process_rank == 0)
        {
            for(int i = 1; i < num_processes; i++)
            {
                MPI_Send(a, 1, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
                MPI_Send(b, 1, MPI_DOUBLE, i, 1, MPI_COMM_WORLD);
                MPI_Send(n, 1, MPI_INT, i, 2, MPI_COMM_WORLD);
            }
        }
        else
        {
            MPI_Recv(a, 1, MPI_DOUBLE, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);
            MPI_Recv(b, 1, MPI_DOUBLE, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);
            MPI_Recv(n, 1, MPI_INT, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);


            printf("a = %lf (Process - %d)\n", *a, process_rank);
            printf("b = %lf (Process - %d)\n", *b, process_rank);
            printf("n = %d (Process - %d)\n", *n, process_rank);
        }
        
    }


    else
    {
        MPI_Bcast(a, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD);
        MPI_Bcast(b, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD);
        MPI_Bcast(n, 1, MPI_INT, 0, MPI_COMM_WORLD);


        if(process_rank != 0)
        {
            printf("a = %lf (Process - %d)\n", *a, process_rank);
            printf("b = %lf (Process - %d)\n", *b, process_rank);
            printf("n = %d (Process - %d)\n", *n, process_rank);
        }
    }
    
}


int main(int argc, char **argv)
{
    double a, b;
    int n, b_flag;


    int process_rank, num_processes;


    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &process_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &num_processes);


    if(process_rank == 0)
    {
        printf("Enter 1 to broadcast the values, 0 to not\n");
        scanf("%d", &b_flag);
    }


    // Broadcasting b_flag alone
    MPI_Bcast(&b_flag, 1, MPI_INT, 0, MPI_COMM_WORLD);


    get_input(&a, &b, &n, process_rank, num_processes, b_flag);


    MPI_Finalize();
}